{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMjt/ISR3nf7Ajdz2KHTVxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwaldenphd/python-structured-data/blob/main/python_structured_data_lab_procedure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Data & File I/O in Python\n",
        "\n",
        "<a href=\"http://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license\"><img style=\"border-width: 0;\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" alt=\"Creative Commons License\" /></a>This tutorial was written by Katherine Walden and is licensed under a <a href=\"http://creativecommons.org/licenses/by-nc/4.0/\" rel=\"license\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.\n"
      ],
      "metadata": {
        "id": "UfKrmequSFVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Overview & Goals\n",
        "\n",
        "This first part of this lab provides an overview of fundamental programming concepts in the areas of file I/O and working with structured data, with a focus on Python syntax. Topics covered include:\n",
        "- Delimited (`.csv`, `.tsv`) and name-value (`.json`, `.xml`) data structures\n",
        "- Escape characters in relation to delimited data structures\n",
        "- Working with delimited and name-value data structures in the Python programming environment, with a focus on the `csv` + `json` modules and `list` + `dictionary` data structures\n",
        "- File I/O and file methods/access modes, with a focus on Python workflows\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "  <td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=304f6392-3cee-4ba6-8da5-af36013a4191\">Lab overview</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "This second part of this lab covers the core components of `pandas`, including `Series` and `DataFrame` objects. It covers how to manually create and interact with `Series` and `DataFrame` objects in the Python programming environment. It covers loading a structured data file (CSV and JSON) as a `DataFrame`, and sorting, selecting, and filtering the resulting `DataFrame`. The lab also covers common data parsing and wrangling challenges like duplicate entries and missing data.\n",
        "\n",
        "By the end of this lab, students will be able to;\n",
        "- Understand the basic components of `Series` and `DataFrame` objects in `pandas`\n",
        "- Manually create `Series` and `DataFrame` objects in Python using `pandas`\n",
        "- Load a structured data file as a `DataFrame` in Python using `pandas`\n",
        "- Interact with a `DataFrame` using sorting, selecting, and filtering operations\n",
        "- Remove duplicate rows from a `DataFrame`\n",
        "- Understand how to approach common `DataFrame` parsing and loading errors using `pandas`\n",
        "- Understand the basic components of how to handle missing values in a `DataFrame`"
      ],
      "metadata": {
        "id": "tuVwZ-DNSGT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Acknowledgements\n",
        "\n",
        "Peer review and editing on the CSV portion of this lab was provided by Spring 2021 graduate teaching assistant [Aidan Draper](https://github.com/adraper2).\n",
        "\n",
        "Peer review and editing on the JSON portion of this lab was provided by Spring 2021 graduate teaching assistant [Subhadyuti Sahoo](https://github.com/SDSAHOO703).\n",
        "\n",
        "When building the CSV, JSON & file methods sections, the author consulted the following materials:\n",
        "- Al Sweigart [*Automate the Boring Stuff With Python*](https://nostarch.com/automatestuff2) (No Starch Press, 2020).\n",
        "  * Chapter 16 \"Working With CSV Files and JSON Data\" (371-388)\n",
        "- Wes McKinney, \"Chapter 6.1, Reading and Writing Data in Text Format\" in [*Python for Data Analysis*](https://www.oreilly.com/library/view/python-for-data/9781491957653/) (O'Reilly, 2017): 169-184.\n",
        "- Wes McKinney, Chapter 6 \"Data Loading, Storage, and File Formats\" from [*Python for Data Analysis*](https://www.oreilly.com/library/view/python-for-data/9781491957653/) (O'Reilly, 2018): 169-193\n",
        "\n",
        "Information and exercises in the pandas sections were developed in consultation with the following resources:\n",
        "- `pandas` package [\"Getting started\"](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/) documentation.\n",
        "- Wes McKinney's [*Python for Data Analysis: Data Wrangling With pandas, Numpy, and IPython*](https://www.oreilly.com/library/view/python-for-data/9781491957653/) (O'Reilly, 2017)\n",
        "  * Chapter 5 \"Getting Started with pandas\" (125-168)\n",
        "  * Chapter 7 \"Data Cleaning and Preparation\" (195-224)\n",
        "  * Chapter 8 \"Data Wrangling: Join, Combine, and Reshape\" (225-256)\n",
        "  * Chapter 10 \"Data Aggregation and Group Operations\" (293-322)"
      ],
      "metadata": {
        "id": "-A8tK4pESHQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture & Live Coding\n",
        "\n",
        "Throughout this lab, you will see a Panopto icon at the start of select sections.\n",
        "\n",
        "This icon indicates there is lecture/live coding asynchronous content that accompanies this section of the lab.\n",
        "\n",
        "You can click the link in the figure caption to access these materials (ND users only).\n",
        "\n",
        "Example:\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "  <td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=304f6392-3cee-4ba6-8da5-af36013a4191\">Lab overview</a></td>\n",
        "  </tr>\n",
        "  </table>"
      ],
      "metadata": {
        "id": "yEnm_PmcdQTS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Concepts\n",
        "\n",
        "[Click here](https://github.com/kwaldenphd/python-structured-data/blob/main/key-concepts.md) for a full list of key concepts and definitions from this lab."
      ],
      "metadata": {
        "id": "YM6xX5lJSJHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Notebook Template\n",
        "\n",
        "[Click here](https://colab.research.google.com/drive/1w6rrEM6I69TIdm-WpSDrEMgMC26bTzdj?usp=sharing) to access the lab notebook template as a Jupyter Notebook"
      ],
      "metadata": {
        "id": "42ZyUxuDSKyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to submit this lab (and show your work)\n",
        "\n",
        "Moving forward, we're going to be submitting lab notebooks using the provide Jupyter Notebook template.\n",
        "- If working in JupyterLab (or another desktop IDE), download the `.ipynb` file to your local computer\n",
        "  * `File` - `Download` - `Download as .ipynb`\n",
        "- If working in Google Colaboratory, MAKE SURE you save a copy to your local drive. Otherwise your changes will not be saved.\n",
        "  * `File` - `Save a copy in Drive`\n",
        "\n",
        "The lab notebook template includes all of the questions as well as pre-created markdown cells for narrative text answers and pre-created code cells for any programs you may need to create.\n",
        "- Double click on these cells to edit and add your own content\n",
        "- If questions do not require a code component, you can ignore those cells\n",
        "- If questions to not require a narrative component, you can ignore those cells\n",
        "\n",
        "If working in JupyterLab or another desktop IDE, upload the lab notebook template `.ipynb` file to Canvas as your lab submission.\n",
        "\n",
        "If working in Google Colaboratory, submit the link to your notebook (checking sharing permissions, similar with Google Docs)."
      ],
      "metadata": {
        "id": "owH_07G3dVDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "You'll need four data files for this lab.\n",
        "- `example.csv` ([GitHub](https://raw.githubusercontent.com/kwaldenphd/python-structured-data/main/data/example.csv), [Google Drive](https://drive.google.com/file/d/1loSl4xUf3ElVgWMfWai3SR3vpGhMK6MS/view?usp=drive_link))\n",
        "- `example.txt` ([GitHub](https://raw.githubusercontent.com/kwaldenphd/python-structured-data/main/data/example.txt), [Google Drive](https://drive.google.com/file/d/1Snl-QnDBz7X2qxf5SdXTd1b0Wc_4ysR5/view?usp=drive_link))\n",
        "- `example.xlsx` ([GitHub](https://github.com/kwaldenphd/python-structured-data/blob/main/data/example.xlsx), [Google Drive](https://docs.google.com/spreadsheets/d/1qh2ympB2aLcSDl-u8r6VD08xePTtsun7/edit?usp=drive_link))\n",
        "- `exampleWithHeader.csv` ([GitHub](https://raw.githubusercontent.com/kwaldenphd/python-structured-data/main/data/exampleWithHeader.csv), [Google Drive](https://drive.google.com/file/d/1lZwUzM3rPzzWqyl6RWquGB_Xtk2EPxlR/view?usp=drive_link))\n",
        "\n",
        "You can also access them [via Google Drive](https://drive.google.com/drive/folders/1Sp_N34753ONJRU2AFKcocQ2DhCEhyL-m?usp=sharing) (ND users only).\n",
        "\n",
        "You'll need to download these files and put them in the same folder as your Jupyter Notebook (or upload them to Google Colab)."
      ],
      "metadata": {
        "id": "gP9gFxV8SUsd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "  <td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=304f6392-3cee-4ba6-8da5-af36013a4191\">Lab overview</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "In programming languages and computing more broadly, `I/O` stands for `Input` and `Output`.\n",
        "\n",
        "We've seen `I/O` at work in previous labs, where we provided inputs to the computer (using a CPU simulator or working at the terminal), a task or operation was performed, and there was an endpoint or output for that process. A concrete example would be the assembly language program we wrote for Lab #2: How Comptuters Work (Hardware). We wrote assembly language instructions which served as inputs for the fetch-execute cycle, and the final output for the program was a data value stored in main memory.\n",
        "\n",
        "Similarly, programming languages can take a variety of inputs (user-provided values, data, files, etc) and return outputs in a variety of formats (data stored in memory, output that shows up in the console, newly-created or -modified files, etc). We've seen `I/O` in action in previous labs, with Python's `print()` and `input()` functions.\n",
        "\n",
        "In this lab, we're going to look at aspects of `I/O` that have to do with reading and writing files, with a focus on two key data structures:\n",
        "- Tabular data, or data stored as a table consisting of rows and columns\n",
        "- Data stored as name-value pairs, specifically in the JavaScript Object Notation (`.json`) format\n",
        "\n",
        "We'll do so by interacting with Python's `csv` module and `json` package, along with the `pandas` Python library.\n"
      ],
      "metadata": {
        "id": "hVxW0cCgSXBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# File I/O & Access Modes\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "  <td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=73668810-b5ed-4fc2-b606-af36012da392\">File I/O in Python</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "Before we start loading data files in Python, let's talk more about how programming languages handle creating, reading, and writing files.\n",
        "\n",
        "From Busbee and Braunschweig's \"[File Input and Output](https://press.rebus.community/programmingfundamentals/chapter/file-input-and-output/),\" in *Programming Fundamentals*:\n",
        "\n",
        "<blockquote>\"A computer file is a computer resource for recording data discretely in a computer storage device. Just as words can be written to paper, so can information be written to a computer file.\n",
        "<br><br>\n",
        "\"There are different types of computer files, designed for different purposes. A file may be designed to store a picture, a written message, a video, a computer program, or a wide variety of other kinds of data. Some types of files can store several types of information at once.\n",
        "<br><br>\n",
        "\"By using computer programs, a person can open, read, change, and close a computer file. Computer files may be reopened, modified, and copied an arbitrary number of times.\"</blockquote>\n",
        "\n",
        "To break that down:\n",
        "- Files store information\n",
        "- Files have different formats or types\n",
        "- Core file tasks (when working in a programming environment): `open`, `read`, `modify` or `change`, `close`\n",
        "\n",
        "We will be focusing on a few key Python functions for working with files.\n",
        "- `open()`\n",
        "- `read()`\n",
        "- `write()`"
      ],
      "metadata": {
        "id": "i2GjAKW-SZez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `open()`\n",
        "\n",
        "The `open()` function lets us open an existing file or create a new file in Python. For either version of `open()` (new file or existing file), we need to specify the file name (with the file type extension) and access mode.\n",
        "\n",
        "Core syntax for opening an existing file:\n",
        "\n",
        "```Python\n",
        "open(file_name.extension, access_mode)\n",
        "```\n",
        "\n",
        "The file type extension is the string of characters that follows the period after the file name. Examples include `.py`, `.csv`, `.txt`, etc. The types of file handling functions we are covering in this lab will generally only support reading and writing plain-text (or machine-readable) files."
      ],
      "metadata": {
        "id": "VIFqrT6vSlPg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Access Modes\n",
        "\n",
        "The access mode parameter specifies the types of modifications that can be made to the file. It can also specify the type of data or information contained in the file.\n",
        "\n",
        "Possible access mode parameters:\n",
        "\n",
        "<table>\n",
        " <tr>\n",
        "  <th>Parameter</th>\n",
        "  <th>Name</th>\n",
        "  <th>Description</th>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"r\"</code></td>\n",
        "  <td>Read</td>\n",
        "  <td>Opens a file for reading; also the default value</td>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"a\"</code></td>\n",
        "  <td>Append</td>\n",
        "  <td>Opens the file for appending new or additional information; Creates the file if it does not already exist</td>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"w\"</code></td>\n",
        "  <td>Write</td>\n",
        "  <td>Opens the file for writing new information; Creates the file if it does not already exist</td>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"x\"</code></td>\n",
        "  <td>Create</td>\n",
        "  <td>Creates the file if it does not already exist</td>\n",
        " </tr>\n",
        " </table>\n",
        "\n",
        "Additionally, we can specify the type of data contained in the file, or how Python should handle the information in the file.\n",
        "\n",
        "<table>\n",
        " <tr>\n",
        "  <th>Parameter</th>\n",
        "  <th>Name</th>\n",
        "  <th>Description</th>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"t\"</code></td>\n",
        "  <td>Text</td>\n",
        "  <td>Treats file as text data; also the default value</td>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"b\"</code></td>\n",
        "  <td>Binary</td>\n",
        "  <td>Treats the file as binary data</td>\n",
        " </tr>\n",
        " </table>"
      ],
      "metadata": {
        "id": "z6jr5Br9SndB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `open()` examples"
      ],
      "metadata": {
        "id": "b1ciVrhWSoNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # opens an existing text (TXT) file with overwrite permission\n",
        " f = open(\"existing_file.txt\", \"w\")"
      ],
      "metadata": {
        "id": "rLdLLmTFSpLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # opens an existing CSV file and reads the content\n",
        " f = open(\"existing_file.csv\", \"r\")"
      ],
      "metadata": {
        "id": "SWJik2xCSqC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # creates new txt file with write permission\n",
        " f = open(\"new_file.txt\", \"w\")"
      ],
      "metadata": {
        "id": "8DAbG18DSq_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # creates new CSV file without write privileges\n",
        " f = open(\"new_file.csv\", \"x\")"
      ],
      "metadata": {
        "id": "TwQRTOPbSr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run these examples, you will see a newly-created file appear in your environment or project workspace.\n",
        "\n",
        "### `write()`\n",
        "\n",
        "Now that we have a newly-created file in Python, we can use the `write()` function to ***write*** content to that file. Let's say we want to create a `.txt` (plain text) file and write a string to that file. We can do that using `write()`.\n",
        "\n",
        "An example:"
      ],
      "metadata": {
        "id": "PBz82KMBStaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creates new txt file with write permission\n",
        "f = open(\"new_file.txt\", \"w\")\n",
        "\n",
        "# writes string to new file\n",
        "f.write(\"Hello world!\")\n",
        "\n",
        "# closes file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "RdJo0fcBSuaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<blockquote>NOTE: It is <strong><em>very important</em></strong> to <code>close()</code> the file once you are done writing content or making modifications.</blockquote>\n",
        "\n",
        "Another example where we have assigned a string to a variable and write the variable to the `.txt` file:"
      ],
      "metadata": {
        "id": "Pd5Yv8hoSvll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creates new txt file with write permission\n",
        "f = open(\"new_file.txt\", \"w\")\n",
        "\n",
        "# assigns string to variable\n",
        "hello_world = \"Hello world!\"\n",
        "\n",
        "# writes string variable to new file\n",
        "f.write(hello_world)\n",
        "\n",
        "# closes file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "t2SJzuzKSw2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alternate workflow for the same program, using with open\n",
        "with open(\"new_file.txt\", \"w\") as f:\n",
        "\tf.write(\"Hello world!\")"
      ],
      "metadata": {
        "id": "xhLYk4YTecNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can open the `new_file.txt` file to see the newly-added content.\n",
        "\n",
        "For more on file handling methods in Python:\n",
        "- [Python File Handling, W3Schools](https://www.w3schools.com/python/python_file_handling.asp)\n",
        "- [Python File Write, W3Schools](https://www.w3schools.com/python/python_file_write.asp)\n",
        "- [Python open() Function](https://www.w3schools.com/python/ref_func_open.asp)\n"
      ],
      "metadata": {
        "id": "aHRhUIbQSyKi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured Data\n",
        "\n",
        "<table>\n",
        "<tr><td><p align=\"center\"><img src=\"https://github.com/kwaldenphd/python-structured-data/blob/main/images/One_Dimensional_Array.jpg?raw=true\" width=\"500\"></p></td><td><p align=\"center\"><img src=\"https://github.com/kwaldenphd/python-structured-data/blob/main/images/Associative_Arrays.png?raw=true\" width=\"500\"></p></td></tr>\n",
        "\t<tr><td align=\"center\">Linear Array</td><td align=\"center\">Associative Array</td></tr></table>\n",
        "\n",
        "In this lab, we're going to look at aspects of `I/O` that have to do with reading and writing files, with a focus on two key data structures:\n",
        "- Tabular data, or data stored as a table consisting of rows and columns\n",
        "- Data stored as name-value pairs, specifically in the JavaScript Object Notation (`.json`) format\n",
        "\n",
        "We can connect these two types of data structures back to the concepts of linear and associative arrays covered previously in the course. A quick refresher:\n",
        "- \"In computer science, an array is a data structure consisting of a collection of elements (values or variables), each identified by at least one array index or key...The simplest type of data structure is a linear array, also called one-dimensional array\" ([Wikipedia, \"Array (data structure)](https://en.wikipedia.org/wiki/Array_(data_structure))\")\n",
        "- Associative arrays are \"an abstract data type that stores a collection of (key, value) pairs, such that each possible key appears at most once in the collection\" ([Wikpedia, Associative Array](https://en.wikipedia.org/wiki/Associative_array))"
      ],
      "metadata": {
        "id": "OE_f-6r3Sz6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delimited Data\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/kwaldenphd/python-structured-data/blob/main/images/table_diagram.png?raw=true\" width=\"1000\"></p>\n",
        "\n",
        "\"A delimited file is a sequential file with column delimiters. Each delimited file is a stream of records, which consists of fields that are ordered by column. Each record contains fields for one row. Within each row, individual fields are separated by column delimiters. All fields must be delimited character strings, non-delimited character strings, or external numeric values. Delimited character strings can contain column delimiters and can also contain character string delimiters when two successive character string delimiters are used to represent one character.\" (IBM, \"[Delimited File Format](https://www.ibm.com/docs/en/db2-for-zos/11?topic=utilities-delimited-file-format)\", 5 February 2022)\n",
        "\n",
        "One of the most common examples of a delimited data structure is a table, with file formats you may open using spreadsheet programs like Microsoft Excel, Google Sheets, or Apple Numbers. However, the file formats associated with spreadsheet programs (`.xlsx` for Microsoft Excel and `.numbers` for Numbers) are NOT plain-text formats. Try to open these file types in a text editor and you'll quickly see the additional content and markup added by the spreadsheet program.\n",
        "\n",
        "For this lab, we'll be working with the `.csv` file type. CSV stands for \"comma-separated values.\" CSV files are tabular data structures (i.e. a spreadsheet), stored in a plain-text format. In `.csv` files, each line represents a row in the spreadsheet, and commas separate cells in each row (thus the file format name comma-separated values). At first glance, `.csv` files look similar to proprietary spreadsheet program file formats, such as files saved in Microsoft Excel or Apple Numbers.\n",
        "\n",
        "A few characteristics that distinguish `.csv` files (or other plain-text delimited data formats) from proprietary spreadsheet file types:\n",
        "- Columns in a `.csv` file don't have a value type. Everything is a string.\n",
        "- Values in a `.csv` file don't have font or color formatting\n",
        "- `.csv` files only contain single worksheets\n",
        "- `.csv` files don't store formatting information like cell width/height\n",
        "- `.csv` files don't recognize merged cells or other kinds of special formatting (frozen or hidden rows/columns, embedded images, etc.)\n",
        "\n",
        "Given these limitations, especially compared to the way we often interact with spreadsheet programs like Microsoft Excel or Google Sheets, what's the advantage of working with `.csv` files? One key advantage of `.csv` files is their simplicity. You can load or open a `.csv` file in a text editor and be able to quickly see the values in the file. When working with data in a programming environment, `.csv` files as a plain-text format simplify the process of loading structured data."
      ],
      "metadata": {
        "id": "gKJs3zckS2dn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `.csv` Files in Python\n",
        "\n",
        "To recap: `CSV` stands for comma-separated values, and `CSV` files are the plain-text, machine-readable file type for tabular data (table data, or data in a spreadsheet structure)\n",
        "\n",
        "For example, a table that looks like this in a spreadsheet program like Excel or Google Sheets:\n",
        "\n",
        "<table>\n",
        " <tr>\n",
        "  <th>Parameter</th>\n",
        "  <th>Name</th>\n",
        "  <th>Description</th>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"t\"</code></td>\n",
        "  <td>Text</td>\n",
        "  <td>Treats file as text data; also the default value</td>\n",
        " </tr>\n",
        " <tr>\n",
        "  <td><code>\"b\"</code></td>\n",
        "  <td>Binary</td>\n",
        "  <td>Treats the file as binary data</td>\n",
        " </tr>\n",
        " </table>\n",
        "\n",
        "Would look like this as a `.csv`:\n",
        "\n",
        "```CSV\n",
        "Parameter, Name, Description\n",
        "\"t\", Text, Treats file as text data; also the default value\n",
        "\"b\", Binary, Treats the file as binary data\n",
        "```\n",
        "\n",
        "So when writing data to a `.csv` file, we need Python to understand the row structure and comma-separated syntax for the file type. Specifically, we need Python to understand we are writing individual rows of data to the file, and we need Python to understand that those rows consist of columns of data separated by columns.\n",
        "\n",
        "Thankfully, Python has a built-in [`CSV` module](https://docs.python.org/3/library/csv.html) with specialized functions designed to help with writing `CSV` files. We can import the module using an `import` statement a the start of our program.\n"
      ],
      "metadata": {
        "id": "cjA2TzcyS5Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "7z1R_6WcS6Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<blockquote>Remember Python includes modules, packages, and libraries we can import and use in our programs. A module is a Python file that typically includes specialized functions and variables. Modules typically have <code>.py</code> file extensions. A single or simple directory of modules is called a package. Packages are typically a simple directory with multiple modules.</blockquote>\n",
        "\n",
        "#### `open` & `write`\n",
        "\n",
        "We can create a file using the `open()` function covered in a previous section of the lab."
      ],
      "metadata": {
        "id": "SRA_vSs0S7W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # create new CSV file with write privileges\n",
        " f = open(\"new_file.csv\", \"w\")"
      ],
      "metadata": {
        "id": "R45xSRKnS8Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next step is to create the `writer` object using the `writer()` function from the `csv` module."
      ],
      "metadata": {
        "id": "G7jPrbYZS9ZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create writer object\n",
        "outputWriter = csv.writer(f)"
      ],
      "metadata": {
        "id": "S2BhEoXuS-aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can use the `.writerow()` method to write individual lists as rows in our `.csv` file."
      ],
      "metadata": {
        "id": "_temKBz-S_SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write first row\n",
        "outputWriter.writerow(['Parameter', 'Name', 'Description')]\n",
        "\n",
        "# write second row\n",
        "outputWriter.writerow(['t', 'Text', 'Treats file as text data; also the default value'])\n",
        "\n",
        "# write third row\n",
        "outputWriter.writerow(['b', 'Binary', 'Treats the file as binary data')]"
      ],
      "metadata": {
        "id": "lypLaa05TAeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we have finished writing new rows of data, we can close the file using the `close()` function."
      ],
      "metadata": {
        "id": "h-PuqgD9TBP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f.close()"
      ],
      "metadata": {
        "id": "leH9jEOOTCIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting that all together:"
      ],
      "metadata": {
        "id": "BnnU0cqPTC4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new CSV file with write privileges\n",
        " f = open(\"new_file.csv\", \"w\")\n",
        "\n",
        " # create writer object\n",
        "outputWriter = csv.writer(f)\n",
        "\n",
        "# write first row\n",
        "outputWriter.writerow(['Parameter', 'Name', 'Description')]\n",
        "\n",
        "# write second row\n",
        "outputWriter.writerow(['t', 'Text', 'Treats file as text data; also the default value'])\n",
        "\n",
        "# write third row\n",
        "outputWriter.writerow(['b', 'Binary', 'Treats the file as binary data')]\n",
        "\n",
        "# close file\n",
        "f.close()"
      ],
      "metadata": {
        "id": "fwNfaLEeTEiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out `new_file.csv` to see the newly-created file with rows of data.\n",
        "\n",
        "#### `read`\n",
        "\n",
        "We'll also use the `csv` module to read or load an existing `.csv` file into Python. The `csv` module allows us to create a `reader` object that iterates over lines in a `.csv` file.\n",
        "\n",
        "What does this workflow look like?"
      ],
      "metadata": {
        "id": "Zit8ffZgTGHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# open csv file\n",
        "exampleFile = open('example.csv')\n",
        "\n",
        "# create reader object from lines of data in example.csv file using csv.reader function\n",
        "exampleReader = csv.reader(exampleFile)\n",
        "\n",
        "# create list with rows of data from example.csv file\n",
        "exampleData = list(exampleReader)\n",
        "\n",
        "# output list rows\n",
        "print(exampleData)"
      ],
      "metadata": {
        "id": "IPEp9tMHTHFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll notice that the `exampleData` output is a list of lists, or a list that contains sub-lists. Each row of data from the original `example.csv` file is a sub-list (with field values separated by commas) within the `exampleData` list.\n",
        "\n",
        "Now we can access the value at a particular row and column using the expression `exampleData[row][col]`.\n",
        "- `row` is the index position of one of the lists in `exampleData`.\n",
        "- `col` is the index position of the item located in that list.\n",
        "\n",
        "For example, `exampleData[0][0]` would give us the first string from the first list. `exampleData[0][1]` would give us the second string from the first list.\n",
        "\n",
        "##### Reading `.csv` data using a `for` loop\n",
        "\n",
        "The method we just used to read data from a `.csv` file into Python loads the entire file into memory at once. If we use this method on a large `.csv` file, Python is going to try to load the entire file into memory at once. Which does not bode well for Python or your computer's performance. We can use a `reader` object as part of a `for` loop to iterate through the lines in a `.csv` file and load the file line-by-line.\n",
        "\n",
        "<blockquote>Remember <code>for</code> loops iterate through each item in a series or list of items and performs the content of the loop on each item.</blockquote>\n",
        "\n",
        "What does this workflow look like?"
      ],
      "metadata": {
        "id": "g9lEixJXTJU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# open .csv file\n",
        "exampleFile = open('example.csv')\n",
        "\n",
        "# create reader object from .csv file\n",
        "exampleReader = csv.reader(exampleFile)\n",
        "\n",
        "# iterate through each row in .csv file and print out row content and number\n",
        "for row in exampleReader:\n",
        "  print('Row #' + str(exampleReader.line_num) + ' ' + str(row))"
      ],
      "metadata": {
        "id": "vQNVSYG0TKji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This program imports the `csv` module, makes a `reader` object from the `example.csv` file, and loops through each of the rows in the `reader` object. Each row is a list of values, and each value represents a cell.\n",
        "- The `print()` function prints the current row number and that row's contents.\n",
        "- The `reader` object includes a `line_num` variable, which contains the number of the current line.\n",
        "\n",
        "<blockquote>NOTE: The <code>reader</code> object can only be looped over once. If you need to re-read the same <code>.csv</code> file, you'll use <code>csv.reader()</code> to create a new <code>reader</code> object.</blockquote>\n",
        "\n",
        "##### Reading `.csv` data as a `dictionary`\n",
        "\n",
        "For `.csv` files that contain header rows, we might want to connect the header row values with subsequent row values. We can do this by reading the `.csv` file as a dictionary, rather than a list containing row sub-lists. Remember dictionaries have key-value pairs, where we can access a value by using its key name. For tabular data, we can think of the key as the field name contained in the header row and the value as column or field values.\n",
        "\n",
        "We read a `.csv` file to a dictionary using a `DictReader` object (versus the `csv.reader` object)."
      ],
      "metadata": {
        "id": "FvGwVxRFTMir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# open csv file\n",
        "exampleFile = open('exampleWithHeader.csv')\n",
        "\n",
        "# reading exampleFile to a DictReader object\n",
        "exampleDictReader = csv.DictReader(exampleFile)\n",
        "\n",
        "# outputs DictReader object as a dictionary\n",
        "for line in exampleDictReader:\n",
        "\tprint(line)"
      ],
      "metadata": {
        "id": "_km7J3HnTNv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Within the `for` loop, the `DictReader` object sets `row` to a dictionary object with keys derived from the headers in the first row. The `DictReader` object means we don't have to separate the header information from the rest of the data contained in the file, because the `DictReader` object does this for us.\n",
        "\n",
        "But what can we do if we want to read to a dictionary a `.csv` file that doesn't incldue a header row? We can pass a second argument to the `DictReader()` function to manually set header names.\n",
        ""
      ],
      "metadata": {
        "id": "i7AE-jJ6TPBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# open csv file\n",
        "exampleFile2 = open('example.csv')\n",
        "\n",
        "# reading exampleFile to a dictionary with added field names\n",
        "exampleDictReader2 = csv.DictReader(exampleFile, ['time', 'name', 'amount'])\n",
        "\n",
        "# set keys for key-value pairs\n",
        "for row in exampleDictReader2:\n",
        "  print(row)"
      ],
      "metadata": {
        "id": "3TJkv3bTTP6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `write`\n",
        "\n",
        "To write data to a `.csv` file in Python, we can create a `writer` object using the `csv.writer()` function to write data to a `.csv` file."
      ],
      "metadata": {
        "id": "xCPLtVnyTQ4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# create and open output.csv file in write mode\n",
        "outputFile = open('output.csv', 'w')\n",
        "\n",
        "# create writer object\n",
        "outputWriter = csv.writer(outputFile)\n",
        "\n",
        "# write first row\n",
        "outputWriter.writerow(['spam', 'eggs', 'bacon', 'ham'])\n",
        "\n",
        "# write another row\n",
        "outputWriter.writerow(['Hello, world!', 'eggs', 'bacon', 'ham'])\n",
        "\n",
        "# write a third row\n",
        "outputWriter.writerow([1, 2, 3.141592, 4])\n",
        "\n",
        "# close the output file\n",
        "outputFile.close()"
      ],
      "metadata": {
        "id": "vHkE2ttZTSAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `writerow()` method takes a list argument and writes that to a new row in the `writer` object, that is added to the `.csv` file.\n",
        "\n",
        "##### Writing from a dictionary to a `.csv` file\n",
        "\n",
        "We can use a `DictWriter` object to write data in a dictionary to a `.csv` file."
      ],
      "metadata": {
        "id": "RefUMP6sTTOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# create and open output.csv file in write mode\n",
        "outputFile = open('output.csv', 'w')\n",
        "\n",
        "# create writer object\n",
        "outputDictWriter = csv.DictWriter(outputFile, ['Name', 'Pet', 'Phone'])\n",
        "\n",
        "# create header row\n",
        "outputDictWriter.writeheader()\n",
        "\n",
        "# write first row\n",
        "outputDictWriter.writerow({'Name': 'Alice', 'Pet': 'cat', 'Phone': '555-1234'})\n",
        "\n",
        "# write another row\n",
        "outputDictWriter.writerow({'Name': 'Bob', 'Phone': '555-9999'})\n",
        "\n",
        "# write a third row\n",
        "outputDictWriter.writerow({'Phone': '555-5555', 'Name': 'Carol', 'Pet': 'dog'})\n",
        "\n",
        "# close the output file\n",
        "outputFile.close()"
      ],
      "metadata": {
        "id": "ENRAeHQYTVIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the order of the key-value pairs in the dictionaries created manually using `writerow()` doesn't matter. Python writes the dictionaries to the `.csv` file using the order of the keys given to `DictWriter()`. Missing keys will be empty in the newly-created `.csv` file.\n",
        "\n",
        "### Application\n",
        "\n",
        "Q1A: Create a small list data structure and write it to a CSV file. Answer to this question includes program + comments that document process and explain your code.\n",
        "\n",
        "Q1B: Create a small dictionary and write it to a CSV file. Answer to this question includes program + comments that document process and explain your code."
      ],
      "metadata": {
        "id": "s1_ceJEkTUjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Delimiters\n",
        "\n",
        "What happens if you need to load in structured data that uses another delimiter, not a comma? Remember when we opened a `.csv` file in a plain-text editor, the value fields are separated by a comma.\n",
        "\n",
        "But commas are not the only possible delimiter. Tabs, spaces, pipes, or other characters can be used to separate or delimit fields in a dataset.\n",
        "\n",
        "<table>\n",
        "\t<tr>\n",
        "\t\t<td>Delimiter Name</td>\n",
        "\t\t<td>Symbol</td>\n",
        "\t\t<td>Python Expression</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td>Tab</td>\n",
        "\t\t<td><code>\\t</code></td>\n",
        "\t\t<td><code>delimiter = \"\\t\"</code></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td>Space</td>\n",
        "\t\t<td><code> </code></td>\n",
        "\t\t<td><code>delimiter = \" \"</code></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td>Pipe</td>\n",
        "\t\t<td><code>|</code></td>\n",
        "\t\t<td><code>delimiter = \"|\"</code></td>\n",
        "\t</tr>\n",
        "\t</table>\n",
        "\n",
        "The `csv` module includes a range of formatting parameters, known as a `Dialect` class. The `Dialect` class includes a range of methods you can use to specify alternate delimiters and (as we'll discover shortly), handle situations like special characters, line breaks, etc.\n",
        "\n",
        "The `delimiter` attribute in the `Dialect` class lets us specify what delimiter is being used in the data we want to load. An example we'll come back to in application questions for this section of the lab:"
      ],
      "metadata": {
        "id": "00ZhIqfSaZ9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import csv module\n",
        "import csv\n",
        "\n",
        "# load tab-separated value file\n",
        "tsv_file = open(FILE NAME)\n",
        "\n",
        "# create a reader object and specify the new delimiter\n",
        "read_tsv = csv.reader(tsv_file, delimiter=SPECIFY DELIMITER HERE)\n",
        "\n",
        "# use a for loop to read in the data\n",
        "for row in read_tsv:\n",
        "  print(row)"
      ],
      "metadata": {
        "id": "OjyOKfJbab4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JavaScript Object Notation\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/kwaldenphd/python-structured-data/blob/main/images/JSONSample.jpg?raw=true\" width=\"500\"></p>\n",
        "\n",
        "JavaScript Object Notation (JSON) is as popular way to format data as a single (purportedly human-readable) string. JavaScript programs use JSON data structures, but we can frequently encounter JSON data outside of a JavaScript environment.\n",
        "\n",
        "Websites that make machine-readable data available via an application programming interface (API- more on these in an upcoming lab) often provide that data in a JSON format. Examples include Twitter, Wikipedia, Data.gov, etc. Most live data connections available via an API are provided in a JSON format.\n",
        "\n",
        "JSON structures can vary WIDELY depending on the specific data provider, but this lab will cover some basic elements of working with JSON in Python. The easiest way to think of JSON data as a plain-text data format made up of something like key-value pairs, like we've encountered previously in working with dictionaries (as a type of associative array).\n",
        "\n",
        "Example JSON string: `stringOfJsonData = '{\"name\": Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'`. From looking at the example string, we can see field names or keys (`name`, `isCat`, `miceCaught`, `felineIQ`) and values for those fields.\n",
        "\n",
        "To use more precise terminology, JSON data has the following attributes:\n",
        "- uses name/value pairs\n",
        "- separates data using commas\n",
        "- holds objects using curly braces `{}`\n",
        "- holds arrays using square brackets `[]`\n",
        "\n",
        "In our example `stringOfJsonData`, we have an object contained in curly braces. An object can include multiple name/value pairs. Multiple objects together can form an array.\n",
        "\n",
        "How is data stored in a JSON format different than a `.csv`?\n",
        "- A `.csv` file uses characters as delimiters and has more of a tabular (table-like) structure.\n",
        "- `.json` data uses characters as part of the syntax, but not in the same way as delimited data files.\n",
        "- The data stored in a JSON format has values that are attached to names (or keys).\n",
        "  * NOTE: We can mimic this structure somewhat by loading a `.csv` as a dictionary data structure\n",
        "- JSON can also have a hierarchical or nested structure, in that objects can be stored or nested inside other objects as part of the same array.\n",
        "\n",
        "For example, take a look at sample JSON data from Twitter's API:\n",
        "\n",
        "```JSON\n",
        "{\n",
        "  \"created_at\": \"Thu Apr 06 15:24:15 +0000 2017\",\n",
        "  \"id_str\": \"850006245121695744\",\n",
        "  \"text\": \"1\\/ Today we\\u2019re sharing our vision for the future of the Twitter API platform!\\nhttps:\\/\\/t.co\\/XweGngmxlP\",\n",
        "  \"user\": {\n",
        "    \"id\": 2244994945,\n",
        "    \"name\": \"Twitter Dev\",\n",
        "    \"screen_name\": \"TwitterDev\",\n",
        "    \"location\": \"Internet\",\n",
        "    \"url\": \"https:\\/\\/dev.twitter.com\\/\",\n",
        "    \"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \\u2328\\ufe0f #TapIntoTwitter\"\n",
        "  },\n",
        "  \"place\": {   \n",
        "  },\n",
        "  \"entities\": {\n",
        "    \"hashtags\": [      \n",
        "    ],\n",
        "    \"urls\": [\n",
        "      {\n",
        "        \"url\": \"https:\\/\\/t.co\\/XweGngmxlP\",\n",
        "        \"unwound\": {\n",
        "          \"url\": \"https:\\/\\/cards.twitter.com\\/cards\\/18ce53wgo4h\\/3xo1c\",\n",
        "          \"title\": \"Building the Future of the Twitter API Platform\"\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \"user_mentions\": [     \n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "<blockquote>Q2: Decipher what we're seeing in the JSON here. What are some of the name/value pairs, and how are they organized in this object?</blockquote>"
      ],
      "metadata": {
        "id": "zNwi5CxGThMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading JSON into Python\n",
        "\n",
        "We can read JSON into Python using the `json` module, which includes a few key functions for loading JSON data into Python:\n",
        "- `json.loads()` takes a single string of JSON and loads it as a Python value\n",
        "- `json.load()` takes a JSON file (or file-like object) and loads it as a Python value\n",
        "- `json.dumps()` takes a Python value and transforms it to a JSON object.\n",
        "\n",
        "<blockquote><a href=\"https://docs.python.org/3/library/json.html\">Click here</a> to learn more about the <code>json</code> module.</blockquote>\n",
        "\n",
        "Values stored in JSON format must be one of the following data types:\n",
        "- string\n",
        "- number\n",
        "- object (JSON object)\n",
        "- array\n",
        "- boolean\n",
        "- null\n",
        "\n",
        "Translation table for how Python's `json` module interprets or renders these data types:\n",
        "\n",
        "JSON | Python\n",
        "--- | ---\n",
        "object | dict\n",
        "array | list\n",
        "string | str\n",
        "number (int) | int\n",
        "number (real) | float\n",
        "true | True\n",
        "false | False\n",
        "null | None\n",
        "\n",
        "To translate a string of JSON data into a Python value, we pass it to the `loads()` function contained in the `json` module."
      ],
      "metadata": {
        "id": "j8-x4bRMTju3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# string of JSON data\n",
        "stringOfJsonData = '{\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'\n",
        "\n",
        "# load JSON data as Python value\n",
        "jsonDataAsPythonValue = json.loads(stringOfJsonData)\n",
        "\n",
        "# output JSON string as Python value\n",
        "jsonDataAsPythonValue"
      ],
      "metadata": {
        "id": "JS-uBZ9zTlDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block of code imports the `json` module, calls the `loads()` function and passes a string of JSON data to the `loads()` function. A few notes on this workflow:\n",
        "- JSON strings always use double quotes, which is rendered in Python as a dictionary. Because Python dictionaries are not ordered, the order of the Python dictionary may not match the original JSON string order.\n",
        "- In this example, we are loading a single string of JSON, which means we use the `json.loads()` function. When loading a JSON file (or file-like object), we would need to use the `json.load()` argument.\n",
        "\n",
        "## Working with JSON in Python\n",
        "\n",
        "Now that the JSON data is stored as a dictionary in Python, we can interact with it via the functionality avaialble via Python dictionaries. We could get all of the keys in the dictionary using the `keys()` method.\n"
      ],
      "metadata": {
        "id": "flBMj-RTTmR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# string of JSON data\n",
        "stringOfJsonData = '{\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'\n",
        "\n",
        "# load JSON data as Python value\n",
        "jsonDataAsPythonValue = json.loads(stringOfJsonData)\n",
        "\n",
        "# print list of keys\n",
        "print(jsonDataAsPythonValue.keys())"
      ],
      "metadata": {
        "id": "5yAtr_ADTnSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could get all of the values in the dictionary using the `values()` method."
      ],
      "metadata": {
        "id": "jFB_l3CbToEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# string of JSON data\n",
        "stringOfJsonData = '{\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'\n",
        "\n",
        "# load JSON data as Python value\n",
        "jsonDataAsPythonValue = json.loads(stringOfJsonData)\n",
        "\n",
        "# print list of values\n",
        "print(jsonDataAsPythonValue.values())"
      ],
      "metadata": {
        "id": "AFVZoyX6TpCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could iterate by keys over the items in the dictionary."
      ],
      "metadata": {
        "id": "k_HdN3faTp10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# string of JSON data\n",
        "stringOfJsonData = '{\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'\n",
        "\n",
        "# load JSON data as Python value\n",
        "jsonDataAsPythonValue = json.loads(stringOfJsonData)\n",
        "\n",
        "# iterate by keys using for loop\n",
        "for key in jsonDataAsPythonValue.keys():\n",
        "  print(key, jsonDataAsPythonValue[key])"
      ],
      "metadata": {
        "id": "wJ5I4LgmTrIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also iterate over items in dictionary using key-value pairs."
      ],
      "metadata": {
        "id": "MZ8ogk6vTr3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# string of JSON data\n",
        "stringOfJsonData = '{\"name\": \"Zophie\", \"isCat\": true, \"miceCaught\": 0, \"felineIQ\": null}'\n",
        "\n",
        "# load JSON data as Python value\n",
        "jsonDataAsPythonValue = json.loads(stringOfJsonData)\n",
        "\n",
        "# iterate by key value pairs using for loop\n",
        "for key, value in jsonDataAsPythonValue.items():\n",
        "  print(key, value)"
      ],
      "metadata": {
        "id": "E8aJlbXjTsvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can read the value for a particular key using the index operator. The command `jsonDataAsPythonValue['name']` will return `Zophie`.\n",
        "\n",
        "In situations where JSON data includes nested or hierarchical objects and arrays, we will end up with a list of dictionaries in Python. For example, let's say we have a different JSON example and want to use more complex expressions in Python."
      ],
      "metadata": {
        "id": "f0Z5BxOYTtzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# new json data\n",
        "data = '''\n",
        "[\n",
        "  { \"id\" : \"001\",\n",
        "    \"x\" : \"2\",\n",
        "    \"name\" : \"Chuck\"\n",
        "  } ,\n",
        "  { \"id\" : \"009\",\n",
        "    \"x\" : \"7\",\n",
        "    \"name\" : \"Brent\"\n",
        "  }\n",
        "]'''\n",
        "\n",
        "#load data as json\n",
        "info = json.loads(data)\n",
        "\n",
        "# print number of users\n",
        "print('User Count:', len(info))\n",
        "\n",
        "# use for loop to print list of names, IDs, and attributes\n",
        "for item in info:\n",
        "  print('Name', item['name'])\n",
        "  print('Id', item['id'])\n",
        "  print('Attribute', item['x'])"
      ],
      "metadata": {
        "id": "GYX1KMenTvqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we loaded a single string of JSON, which means we use the `loads()` function. When loading a JSON file (or file-like object), we would need to use the `load()` argument.\n",
        "\n",
        "For more on working with dictionaries in Python:\n",
        "- [Elements of Computing I lab](https://github.com/kwaldenphd/python-next-steps/blob/main/part-i.md#dictionaries)\n",
        "- [W3 Schools tutorial](https://www.w3schools.com/python/python_dictionaries.asp)\n",
        "\n",
        "## Writing to JSON from Python\n",
        "\n",
        "The `json` module's `dumps()` function will translate a Python dictionary into a string of JSON-formatted data.\n"
      ],
      "metadata": {
        "id": "6kTyhmc2TxGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# Python dictionary\n",
        "pythonValue = {'isCat': True, 'miceCaught': 0, 'name': 'Zophie', 'felineIQ': None}\n",
        "\n",
        "# translate Python value to JSON string\n",
        "stringOfJsonData = json.dumps(pythonValue)\n",
        "\n",
        "stringOfJsonData"
      ],
      "metadata": {
        "id": "_HSMPb2ITy6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also write data in a Python dictionary to a JSON file also using `dump()`."
      ],
      "metadata": {
        "id": "PrzRcPKtTz9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json module\n",
        "import json\n",
        "\n",
        "# Python dictionary\n",
        "pythonValue = {'isCat': True, 'miceCaught': 0, 'name': 'Zophie', 'felineIQ': None}\n",
        "\n",
        "# create new JSON file and write dictionary to file\n",
        "with open('output.json', 'w') as json_file:\n",
        "\tjson.dump(pythonValue, json_file)"
      ],
      "metadata": {
        "id": "9UmZ5ssFT1sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "Q3: Create a string of JSON data and write it to a JSON file. Answer to this question includes program + comments that document process and explain your code."
      ],
      "metadata": {
        "id": "LqQn_RuxT35g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `pandas`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=1a39dca8-2d61-4f20-b6e8-af360144f447\">Overview</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/kwaldenphd/pandas-intro/blob/main/images/Peebo.png?raw=true\" width=\"1000\"></p>\n",
        "\n",
        "Some of you may be wondering why we are talking about pandas in a Computer Science course....\n",
        "\n",
        "Panda: \"a large black-and-white mammal (Ailuropoda melanoleuca) of chiefly central China that feeds primarily on bamboo shoots and is now usually classified with the bears (family Ursidae)\" ([Merriam-Webster](https://www.merriam-webster.com/dictionary/panda))\n",
        "\n",
        "Wait that's not right....\n",
        "\n",
        "`pandas`: \"a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language\" ([`pandas` documentation](https://pandas.pydata.org/))\n",
        "\n",
        "That makes more sense.\n",
        "\n",
        "There are limitations to the kinds of things we can do with structured data using the `csv` module. Particularly if we want to analyze and visualze structured data in a Python programming environment, we aren't going to get very far loading `csv` files as lists or dictionaries. We need Python to understand or interact with structured data as structured data.\n",
        "\n",
        "Software developers at AQR Capital Management began working on a Python-based tool (written in a combination of C and Python) for quantitative data analysis in 2008. The initial open-source version of `pandas` was released in 2008.\n",
        "\n",
        "At its core, \"`pandas` is a software library written for the Python programming language for data manipulation and analysis. In particular, it offers data structures and operations for manipulating numerical tables and time series\" ([Wikipedia](https://en.wikipedia.org/wiki/Pandas_(software)). The name `pandas` is derived from \"panel data,\" an econometrics term used to describe particular types of datasets. The name `pandas` is also a play on \"Python data analysis.\"\n",
        "\n",
        "- For more on the history and origins of `pandas`, check out Wes McKinney's [\"pandas: a Foundational Python Library for Data Analysis and Statistics\"](https://www.dlr.de/sc/Portaldata/15/Resources/dokumente/pyhpc2011/submissions/pyhpc2011_submission_9.pdf) 2011 paper.\n",
        "\n",
        "`pandas` is based on and has some similarities with another Python package, `NumPy`. According to [package documentation](https://numpy.org/doc/stable/user/whatisnumpy.html), \"`NumPy` is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\"\n",
        "\n",
        "In `NumPy`, data are stored as list-like objects called arrays. `NumPy` allows users to access, split, reshape, join, etc. data stored in arrays. `pandas` takes a similar approach to structured data, or data organized in a tabular (i.e. table-like) format. \"pandas adopts significant parts of NumPy's idiomatic style of array-based computing, especially array-based functions and a preference for data processing without for loops...the biggest difference is that pandas is designed for working with tabular or heterogeneous data. NumPy, by contrast, is best suited for working with homogenous numerical array data\" (Wes McKinney, Chapter 5 \"Getting Started with Pandas\" in *Python for Data Analysis*, pg. 125)\n",
        "\n",
        "For more on `NumPy`:\n",
        "- [NumPy website](https://numpy.org/)\n",
        "- [NumPy documentation](https://numpy.org/doc/stable/)\n",
        "- [\"NumPy Introduction,\" W3Schools](https://www.w3schools.com/python/numpy_intro.asp)\n",
        "- [\"Introduction to NumPy Tutorial,\" Software Carpentry](https://software-carpentry.org/blog/2012/06/introduction-to-numpy-tutorial.html)"
      ],
      "metadata": {
        "id": "npInfIDyrqfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Structures in `pandas`\n",
        "\n",
        "<p align=\"center\"><img src=\"https://github.com/kwaldenphd/pandas-intro/blob/main/images/series_df_diagram.png?raw=true\" width=\"1000\"></p>\n",
        "\n",
        "`pandas` has two main data structures: `Series` and `DataFrame`.\n",
        "- \"A `Series` is a one-dimensional, array-like object containing a sequence of values...and an associated array of data labels, called its index\" (McKinney, 126)\n",
        "- A `DataFrame` includes a tabular data structure \"and contains an ordered collection of columns, each of which can be a different value type\" (McKinney, 130)."
      ],
      "metadata": {
        "id": "MMoJ_Wf9rtFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `Series`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a6057ced-9dd1-426c-a063-af360146b0dd\">Series</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "In `pandas`, \"a `Series` is a one-dimensional, array-like object containing a sequence of values...and an associated array of data labels, called its index\" (McKinney, 126). At first glance, a `Series` looks a lot like a Python list."
      ],
      "metadata": {
        "id": "ee5ihoNGrt-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas package\n",
        "import pandas as pd\n",
        "\n",
        "# import Series and Data Frame components from pandas\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "# create a Series using pandas\n",
        "obj = pd.Series([4, 7, -5, 3])\n",
        "\n",
        "# show obj Series\n",
        "obj"
      ],
      "metadata": {
        "id": "K8zNavhurvJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few notes on what's happening in this example:\n",
        "- We imported the `pandas` package (using the `pd` alias) as well as the specific `Series` and `DataFrame` components.\n",
        "- We created a `Series` object containing four integer values.\n",
        "\n",
        "We could create a list with these values, but for data analysis we needed the functionality `pandas` provides for working with series. To verify `obj` is stored as an array-like object, we can use `pd.Series(obj).values` which should return `array([4, 7, -5, 3])`\n",
        "\n",
        "We can also get the index attributes for `obj` using `pd.Series(obj).index`, which should return `RangeIndex(start=0, stop=4, step=1)`. The default index attributes assigned to objects in an array are integers `0` through `N-1`, where `N` is the length of the data. We can create our own index attributes for the data points by manually creating index labels.\n"
      ],
      "metadata": {
        "id": "mEd_oGiHrwbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create obj2 series with index attributes\n",
        "obj2 = pd.Series([4, 7, -5, 3], index=['d', 'b', 'a', 'c'])\n",
        "\n",
        "# show obj2 series\n",
        "obj2"
      ],
      "metadata": {
        "id": "hG6m-uwHrxq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The index-value link lets us interact with a `Series` object similar to how we would work with Python dictionary key-value pairs."
      ],
      "metadata": {
        "id": "jANd0Sq3ry-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# access Series value using index label\n",
        "obj2['a']\n",
        "\n",
        "# this returns -5"
      ],
      "metadata": {
        "id": "weAzEa8Yrzxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign value for index\n",
        "obj2['d'] = 6\n",
        "\n",
        "obj2['d']\n",
        "\n",
        "# this returns 6, our newly-assigned value for index 'd'"
      ],
      "metadata": {
        "id": "pBCf6qcer1II"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# access multiple values in Series object using index\n",
        "obj2[['c', 'a', 'd']]\n",
        "\n",
        "# this returns the index-value pairs for the specified index labels"
      ],
      "metadata": {
        "id": "vVInpKPNr2aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use Python's built-in arithmetic functionality for values in a `Series` object."
      ],
      "metadata": {
        "id": "lU9iU_tNr3UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select values in the Series that meet a specific condition\n",
        "obj2[obj2 > 0]\n",
        "\n",
        "# returns index-value pairs for values greater than 0"
      ],
      "metadata": {
        "id": "tE9I5Lm4r4QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiply all values in Series\n",
        "obj * 2\n",
        "\n",
        "# returns modified values"
      ],
      "metadata": {
        "id": "_UPGipRnr5Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform NumPy's exponent calculation functionality on Series values\n",
        "np.exp(obj2)\n",
        "\n",
        "# returns exponent float values"
      ],
      "metadata": {
        "id": "todBuTAtr6DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to perform similar mathematical operations on values stored in a Python dictionary or list and you'll run into all kinds of data type errors. The `Series` object uses a similar data structure and opens up a wide range of analysis possibilities.\n",
        "\n",
        "To create a `Series` from data in a Python dictionary:\n"
      ],
      "metadata": {
        "id": "zMzUSlJkr7Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary\n",
        "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
        "\n",
        "# create Series from dict dictionary\n",
        "obj3 = pd.Series(sdata)"
      ],
      "metadata": {
        "id": "rOp7w8Cir9D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we wanted to have the `Series` values appear in a specific order. We can specify the index (or key) label order when converting a dictionary to a Series."
      ],
      "metadata": {
        "id": "LvbD1fu8r93O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary\n",
        "sdata = {'Ohio': 35000, 'Texas': 71000, 'Oregon': 16000, 'Utah': 5000}\n",
        "\n",
        "# list of index labels\n",
        "states = ['California', 'Ohio', 'Oregon', 'Texas']\n",
        "\n",
        "# create Series from dict dictionary\n",
        "obj4 = pd.Series(sdata, index=states)\n",
        "\n",
        "# see output for new obj4 series\n",
        "obj4"
      ],
      "metadata": {
        "id": "TuyPEWesr-1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few things have happened here.\n",
        "- The `California` index is returning `NaN` for its value, which is \"not a number\" or \"NA\".\n",
        "- The `Utah` value in `sdata` is not in the `obj4` series, because the idex label `Utah` was not in the manually assigned list of index values passed to the series through `index=true`.\n",
        "\n",
        "We can use the `isnull()` or `notnull()` functions in `pandas` to detect missing data. These functions will return `TRUE` or `FALSE`."
      ],
      "metadata": {
        "id": "au6O7EzVsALy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test for null values for each index label\n",
        "pd.isnull(obj4)\n",
        "\n",
        "# output will be FALSE for all but California"
      ],
      "metadata": {
        "id": "l8igNCA1sBRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test for not null values\n",
        "pd.notnull(obj4)\n",
        "\n",
        "# output will be TRUE for all but California"
      ],
      "metadata": {
        "id": "GdnFAB6hsCG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can assign a name for our `Series` object and its index values using the `name` attribute."
      ],
      "metadata": {
        "id": "SzLwjsTKsC45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# assign name to Series object\n",
        "obj4.name = 'population'\n",
        "\n",
        "# assign name to index\n",
        "obj4.index.name = 'state'\n",
        "\n",
        "# view updated Series\n",
        "obj4"
      ],
      "metadata": {
        "id": "6uGMVMgmsDsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output for `obj4` now reflects our newly-assigned `name` attribute values.\n",
        "\n",
        "#### Application\n",
        "\n",
        "Q4: Create your own `Series` object. Write code the accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Assign unique index attributes for each series value\n",
        "- Access a series value(s) using the index label\n",
        "- Perform at least two unique arithmetic operations on the Series\n",
        "- Test for null values in your series"
      ],
      "metadata": {
        "id": "qfUvGmXvsE9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `DataFrame`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=96293510-c88d-4444-a8d0-af360146c587\">DataFrame</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "While a `Series` object is a one-dimensional array, a `DataFrame` includes a tabular data structure \"and contains an ordered collection of columns, each of which can be a different value type\" (McKinney, 130). A `pandas` `DataFrame` has a row and column index--we can think of these as Series that all share the same index. Behold, a two-dimensional data structure!\n",
        "\n",
        "In most situations, you'll create a `DataFrame` by reading in a structured data file. But we're going to manually create a `DataFrame` to better understand how they work in `pandas`. Let's go back to our state population data example. Say we have two dictionaries that include equal-length lists:\n"
      ],
      "metadata": {
        "id": "4nBT7J0MsGiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dictionary with three equal-length lists\n",
        "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
        "        'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
        "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
        "\n",
        "# write data dictionary values to data frame\n",
        "frame = pd.DataFrame(data)\n",
        "\n",
        "# show newly-created frame\n",
        "frame"
      ],
      "metadata": {
        "id": "HJda1JwbsGIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Behold, a two-dimensional `DataFrame` object with rows, columns, labels, and values. The first object from each of the lists in our `data` dictionary now populate the first row of our `frame` DataFrame. This pattern continues for subsequent rows.\n",
        "\n",
        "We can start to explore the dimensions or overall characteristics of our DataFrame:"
      ],
      "metadata": {
        "id": "FgCOkl30sIvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shows index labels and values for first 5 rows\n",
        "frame.head(5)\n",
        "\n",
        "# shows list of column labels\n",
        "frame.columns.values\n",
        "\n",
        "# shows basic statistical information for the data frame\n",
        "frame.describe()"
      ],
      "metadata": {
        "id": "X3U2lA-esJhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last command `.describe()` returns some statistical information about values in our dataset, including:\n",
        "- count\n",
        "- mean\n",
        "- standard deviation\n",
        "- minimum\n",
        "- 25th percentile\n",
        "- 50th percentile\n",
        "- 75th percentile\n",
        "- maximum\n",
        "\n",
        "Let's say we want to specify the column sequence or the order in which columns are arranged in the `DataFrame`:"
      ],
      "metadata": {
        "id": "wtbCDJsLsK1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data, columns=['year', 'state', 'pop'])"
      ],
      "metadata": {
        "id": "wkKlYhyAsL5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if we specify a column that isn't represented in the data passed to the `DataFrame`?"
      ],
      "metadata": {
        "id": "A6UobSRXsMx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new dataframe from data dictionary with specific columns and index labels\n",
        "frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four', 'five', 'six'])\n",
        "\n",
        "# show frame2 DataFrame\n",
        "frame2"
      ],
      "metadata": {
        "id": "0uOPRnuYsN10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see only `NaN` missing values for the `debt` column since that column is not represented in the `data` dictionary used to create our `frame2` DataFrame.\n",
        "\n",
        "We can select columns in our `DataFrame` using their index labels."
      ],
      "metadata": {
        "id": "cAQMPQ6JsOwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2['state']\n",
        "\n",
        "# returns state column"
      ],
      "metadata": {
        "id": "isLNlf02sQBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also select a column using the `name` attribute."
      ],
      "metadata": {
        "id": "0d91o4yvsRd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2.year\n",
        "\n",
        "# returns year column"
      ],
      "metadata": {
        "id": "ihO0yhtrsSUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can retrieve rows based on their position using the `loc` (location) attribute."
      ],
      "metadata": {
        "id": "87pCh_g6sTW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2.loc['three']\n",
        "\n",
        "# returns the third row in the dataframe"
      ],
      "metadata": {
        "id": "33UUxM4TsUGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame2.iloc[0:3, :]\n",
        "\n",
        "# uses numerical index values to retrieve first four rows"
      ],
      "metadata": {
        "id": "tGIUF5KIsVLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's say we wanted to manually assign the values in a particular column, for example the `debt` missing data column."
      ],
      "metadata": {
        "id": "s7y8XdVysV6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame2['debt'] = 16.5\n",
        "\n",
        "frame2\n",
        "\n",
        "# returns frame2 DataFrame with newly-assigned 16.5 value for all rows in debt column"
      ],
      "metadata": {
        "id": "LsGtwoUosXgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could also manually insert values for specific rows using their index labels. If we wanted to add debt values for rows two, four, and five:"
      ],
      "metadata": {
        "id": "QeehA8TlsYV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# variable with Series object\n",
        "val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])\n",
        "\n",
        "# assign val Series object to debt column in frame2 DataFrame\n",
        "frame2['debt'] = val\n",
        "\n",
        "# show modified DataFrame\n",
        "frame2"
      ],
      "metadata": {
        "id": "9zcIvgrgsZH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now see the modified `debt` values for the rows specified in the `index=` portion of our code.\n",
        "\n",
        "We can remove a column using the `del` keyword."
      ],
      "metadata": {
        "id": "k0KLkJOQsZ_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del frame2['debt']\n",
        "\n",
        "# returns updated list of columns\n",
        "frame2.columns\n",
        "\n",
        "# result will be 'year', 'state', and 'pop'"
      ],
      "metadata": {
        "id": "M4xpcEmcsa4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Application\n",
        "\n",
        "Q5: Create your own small DataFrame. Write code that accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Change the original column order\n",
        "- Select a specific column(s) using its index label or name attribute\n",
        "- Select a specific row(s) using its index label or index value\n",
        "- Remove a column from the DataFrame\n",
        "- Determine summary statistics for values in the DataFrame"
      ],
      "metadata": {
        "id": "moBM65T0scQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From Data File to `DataFrame`\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=01168562-ebe4-4516-89ef-af3601451832\">From Data File to DataFrame</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "As mentioned earlier in this lab, it's far more likely that you will load structured data from a file into Python, rather than manually creating a `DataFrame`. For this section of the lab, we're going to work with data about *Titanic* passengers. Navigate to https://raw.githubusercontent.com/kwaldenphd/pandas-intro/main/data/titanic.csv in a web browser to see the dataset.\n",
        "\n",
        "We can load structured data into Python from a file located on our computer or from a URL, using `pd.read_csv()`. An example of how we would load the `titanic.csv` file in Python as a `Pandas` DataFrame:\n"
      ],
      "metadata": {
        "id": "W-YyGiUMsdZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load titanic data from csv file\n",
        "# titanic = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "# load titanic data from url\n",
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/pandas-intro/main/data/titanic.csv\")\n",
        "\n",
        "# show first 5 rows of newly-loaded dataframe\n",
        "titanic.head(5)"
      ],
      "metadata": {
        "id": "F9yJMSfAselB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pandas` provides the `read_csv()` function which stores `.csv` data as a `pandas` `DataFrame`. This `read_` prefix can be used with other structured data file formats, as we'll explore with JSON later.\n",
        "\n",
        "Other parsing functions in `pandas`:\n",
        "- `read_fwf`: fixed-width data with no delimiter\n",
        "- `read_clipboard`: reads in data from clipboard\n",
        "- `read_excel`: reads in data from `.xls` or `.xlsx` files\n",
        "- `read_html`: reads in any tables contained in an HTML document\n",
        "- `read_json`: reads in JSON data\n",
        "- `read_sql`: reads in results of an SQL query as a pandas dataframe\n",
        "- `read_sas`: reads in SAS dataset\n",
        "- `read_stata`: reads in Stata file format\n",
        "\n",
        "To check the first and last five rows of the `titanic` data frame:"
      ],
      "metadata": {
        "id": "ujQfGZY7sgEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic"
      ],
      "metadata": {
        "id": "05NLvpAssgfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check the data type for each column using `.dtypes`."
      ],
      "metadata": {
        "id": "U1IzD1o7shyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.dtypes"
      ],
      "metadata": {
        "id": "P5mChx2Csiah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this output, we know we have integers (`int64`), floats (`float64`), and strings (`object`). Maybe we want a more technical summary of this `DataFrame`."
      ],
      "metadata": {
        "id": "K6LRPK6hsjHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.info()"
      ],
      "metadata": {
        "id": "z-vBsnddsj3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.info()` returns row numbers, the number of entries, column names, column data types, and the number of non-null values in each column. We can see from the `Non-Null Count` values that some columns do have null or missing values. `.info()` also tells us how much memory (RAM) is used to store this `DataFrame`."
      ],
      "metadata": {
        "id": "-8T6WFbbskt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Data Loading Challenges\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=7947cc62-3264-43da-afe4-af360147f936\">Other Data Loading Challenges</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "We can also run into situations where the data we are loading into Python has missing values. We can specify what characters representing missing data when we create the `DataFrame`."
      ],
      "metadata": {
        "id": "2KtGHARisoJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load data where missing values are represented by NA or Null\n",
        "sample = pd.read_csv(\"file_name.csv\", na_values=['NA', 'Null'])\n",
        "\n",
        "# for a situation where missing values in one column are represented by NA and another column's missing data are represented by Null\n",
        "# first step is to create a dictionary for these column names and null values\n",
        "null_symbols = {'column1': ['NA'], 'column2': ['Null']}\n",
        "\n",
        "# load data where with column-specific missing values\n",
        "sample2 = pd.read_csv(\"file_2_name.csv\", na_values=null_symbols)"
      ],
      "metadata": {
        "id": "xS47Il4LspT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`pd.read_csv` includes other function arguments that can help with other common data formatting issues.\n",
        "\n",
        "Argument | Description\n",
        "--- | ---\n",
        "`sep` or `delimiter` | Specifies the character sequence or regular expression used as a separator or delimiter\n",
        "`header` | Specifies the row number to use as column names; `0` is default (does not need to be specified); `header=None` if no header\n",
        "`index_col` | Specifies the column numbers or names to use as row index\n",
        "`names` | Specifies list of column names for result\n",
        "`skiprows` | Row numbers (starting at 0) for rows to skip\n",
        "`na_values` | Sequence of characters that represent missing or NA data\n",
        "`comment` | Characters used to mark or split off comments that occur at end of lines of data\n",
        "`parse_dates` | Specifies how date and time data will be parsed; `False` by default; `True` will attempt to parse all columns as `datetime` format; can also apply to select columns\n",
        "`dayfirst` | Specifies international date format (DD/MM/YYYY); `False` by default\n",
        "`date_parser` | Function used to parse dates\n",
        "`nrows` | Number of rows to read starting at the beginning of the file; especially helpful when only needing part of a large file\n",
        "`skipfooter` | Number of lines to ignore at the end of the file\n",
        "`encoding` | Specifies encoding schema\n",
        "`thousands` | Specifies `,` or `.` separater for thousands\n",
        "\n",
        "Other elements of `.csv` dialect we might encounter when loading a file to a `DataFrame`:\n",
        "\n",
        "Argument | Description\n",
        "--- | ---\n",
        "`delimiter` | One character string used to separate fields; default is `,`\n",
        "`quotechar` | Quote character for fields with specific characters or fields that inclde the delimiter character\n",
        "`skippinitialspace` | Instructs program to ignore whitespace after delimiter; default is `False`\n",
        "`doublequote` | Specifies how to handle quoting character within a field\n",
        "`escapechar` | Specifies the string used to escape the delimiter character if `quoting` is set to `QUOTE_NONE`\n",
        "\n",
        "### Application\n",
        "\n",
        "For the Q6 programs, you do not need to write code that actually loads an existing data file. That is, the lab does not provide data files that include these structures/attributes.\n",
        "\n",
        "Write sample code that shows the syntax you would use to load a file with the structures/attributes described in the question.\n",
        "- HINT: Be prepared to reference and consult the additional pd.read_csv function arguments listed in the previous lab section's tables.\n",
        "\n",
        "Q6A: Write code that loads in a structured data file that uses a pipe symbol (|) as a delimiter. Include code + comments.\n",
        "\n",
        "Q6B: Write code that loads in structured data file in which missing data values are represented by \"?\", \"??\", and \"-\" characters. Include code + comments.\n",
        "\n",
        "Q6C: Write code that ignores the last 6 rows of a structured data file. Include code + comments.\n",
        "\n",
        "Q6D: Write code that parses a structured data file in which commas \",\" are used as a thousands separator. Include code + comments"
      ],
      "metadata": {
        "id": "UlnzNSdbsrfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interacting with a `DataFrame`"
      ],
      "metadata": {
        "id": "9RiaXjPWsuAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=480927f9-34c6-436d-8971-af360146f634\">Sorting</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "`pandas` includes a few different built-in sorting operations. We can sort by an index for either axis of our `DataFrame` (i.e. we can sort based on row index labels or by column name). Going back to our Titanic passenger data, let's say we wanted to sort by passenger age."
      ],
      "metadata": {
        "id": "KdopEvK5su6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# load titanic data from url\n",
        "titanic = pd.read_csv(\"https://raw.githubusercontent.com/kwaldenphd/eda-pandas/main/data/titanic.csv\")\n",
        "\n",
        "# show first 5 rows of newly-loaded dataframe\n",
        "titanic.head(5)\n",
        "\n",
        "# sort by passenger age and show first five rows of the sorted data\n",
        "titanic.sort_values(by=\"Age\").head()"
      ],
      "metadata": {
        "id": "g8n_UMn5sv3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The default for `.sort_values` is to sort in ascending order. We can use `ascending=False` to sort in descending order."
      ],
      "metadata": {
        "id": "B2djDG2hswsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.sort_values(by=['Age'], ascending=False)"
      ],
      "metadata": {
        "id": "kipkPQpksxSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE: When sorting, we are returning a sorted `DataFrame`. We ARE NOT updating the `DataFrame` in place. We have a couple of options to sort in place."
      ],
      "metadata": {
        "id": "jpAttcrfsx0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create new dataframe with sorted results\n",
        "titanic_by_age = titanic.sort_values(by=\"Age\")\n",
        "\n",
        "# check newly-created dataframe\n",
        "titanic_by_age.head()"
      ],
      "metadata": {
        "id": "DqCwF9bQsyvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort values in place\n",
        "titanic.sort_values(['Age'], inplace=True)\n",
        "\n",
        "# check newly-created dataframe\n",
        "titanic.head()"
      ],
      "metadata": {
        "id": "f4a43ckgs0EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also sort by multiple fields. To sort by class cabin and age, in descending order:"
      ],
      "metadata": {
        "id": "zvCT9Sjps0_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "titanic.sort_values(by=['Pclass', 'Age'], ascending=False).head()"
      ],
      "metadata": {
        "id": "-0qntzSDs2DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When sorting by fields with string data, `a-z` is considered `ascending` and `z-a` would be `descending`."
      ],
      "metadata": {
        "id": "s-Ad44ENs2nq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subsetting"
      ],
      "metadata": {
        "id": "qu6gH7Ays3X8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=b2805333-207c-4cc2-9238-af360146fd12\">Select</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "To review, we can select specific columns from a `DataFrame`."
      ],
      "metadata": {
        "id": "dJ2q-g5Es4VO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creates Series object with age values\n",
        "ages = titanic[\"Age\"]\n",
        "\n",
        "# show new object\n",
        "ages"
      ],
      "metadata": {
        "id": "iFpRXNJOs5B9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `[\" \"]` to select a specific single column of interest. Python returns this single column's data as a `Series` object. We can also create a new data frame based on multiple columns."
      ],
      "metadata": {
        "id": "uPqW4vxqs6L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selects multiple columns to form new dataframe\n",
        "age_sex = titanic[[\"Age\", \"Sex\"]]\n",
        "\n",
        "# checks first five rows of new dataframe\n",
        "age_sex.head()"
      ],
      "metadata": {
        "id": "bLcbGzlKs7B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When selecting multiple columns, the inner brackets (`[]`) define the column names to subset or select. The outer brackets select data from a dataframe. In this multi-column example, `age_sex` is a `DataFrame` because it is a two-dimensional object.\n",
        "\n",
        "For more on sorting operations in `pandas`, check out the package's [\"Sorting\" documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#sorting).\n",
        "\n",
        "### Filter\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=9570d7eb-5363-4bca-89ef-af360147074d\">Filter</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "We can use Python's comparison operators to return rows in our `DataFrame` that meet specific conditions. Let's say we wanted to create a new `DataFrame` only containing data for passengers older than 35 years."
      ],
      "metadata": {
        "id": "OsLqNb3Fs8Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "above_35 = titanic[titanic[\"Age\"] > 35]\n",
        "\n",
        "# check first five rows of newly-created dataframe\n",
        "above_35.head()"
      ],
      "metadata": {
        "id": "G8SQ7RvSs8z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use brackets (`[]`) to set a condition rows must meet to be assigned to the new dataframe. If we just wanted to see whether rows meet this condition in the original `DataFrame`, we could just test for the condition without creating a new `DataFrame`."
      ],
      "metadata": {
        "id": "9D_9Iymhs9x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic[\"Age\"] > 35"
      ],
      "metadata": {
        "id": "YO3HaHNds-jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe we want to create a new data frame containing data on passegers in cabin class 2 and 3."
      ],
      "metadata": {
        "id": "mq9rCLc9s_Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_23 = titanic[titanic[\"Pclass\"].isin([2, 3])]\n",
        "\n",
        "# check first five rows of newly-created dataframe\n",
        "class_23.head()"
      ],
      "metadata": {
        "id": "6ECd_E2JtAOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `isin()` conditional function on its own would return a `True` or `False` value. By nesting the `isin()` function in brackets (`[]`), we are filtering rows based on rows  that meet the function critera, or return as `True` from this function.\n",
        "\n",
        "We could also break out the chained or compound conditional statement using an `OR` operator, `|`."
      ],
      "metadata": {
        "id": "36VYAYjLtBjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_23_alternate =  titanic[(titanic[\"Pclass\"] == 2) | (titanic[\"Pclass\"] == 3)]\n",
        "\n",
        "class_23_alternate.head()"
      ],
      "metadata": {
        "id": "l5v22rzgtCdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more on Boolean indexing and the `isin()` function:\n",
        "- [\"Boolean indexing,\" Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-boolean)\n",
        "- [\"Indexing with isin,\" Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-basics-indexing-isin)\n",
        "\n",
        "We could also create a new dataframe with passenger data for only passengers that have a known age."
      ],
      "metadata": {
        "id": "tg0LHCe0tDpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "age_known = titanic[titanic[\"Age\"].notna()]\n",
        "\n",
        "age_known.head()"
      ],
      "metadata": {
        "id": "VnkLv-sxtE99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.notna()` is a conditional function that returns `True` for rows that do not have a `Null` value. For more on missing values and related functions, check out [the \"Working with missing data\" package documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data)."
      ],
      "metadata": {
        "id": "RwyCvRPvtF_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting specific rows and columns\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=a2d95af5-1c38-427b-8251-af360147393c\">Selecting Specific Rows & Columns</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "Selecting lets us isolate columns, and filtering identifies specific rows. But we can imagine a scenario in which we would want to combine these elements. We might want to create a new dataframe containing only the names of passengers who are over 35 years old."
      ],
      "metadata": {
        "id": "HIxd6abbtHa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "over_35_names = titanic.loc[titanic[\"Age\"] > 35, \"Name\"]\n",
        "\n",
        "over_35_names"
      ],
      "metadata": {
        "id": "AGLAOMg-tIGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.loc` identifies the rows we are writing to the new dataframe. What we are passing to the `loc` operator includes the row filter condition (`titanic[\"Age\"] > 35`) and the column we are writing to the new dataframe (`Name`).\n",
        "\n",
        "We can also select rows and columns based on their index position. We could isolate rows 10-25 and columns 3-5 with the following expression:"
      ],
      "metadata": {
        "id": "2OgL0t5etJSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic.iloc[9:25, 2:5]"
      ],
      "metadata": {
        "id": "ysWhqFSttKFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also assign new values to our selection using `loc` or `iloc`. `loc` isolates rows based on their value, while `iloc` isolates rows based on their index position or label. Let's say we wanted to anonymize the first three names in the dataset. We could do this using `titanic.iloc[0:3, 3] = \"anonymous\"`.\n",
        "\n",
        "Consult the [\"Different choices for indexing\"](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#indexing-choice) documentation for more on indexing options.\n",
        "\n",
        "A few key takeaways:\n",
        "- We use square brackets `[]` to subset data.\n",
        "- We can specify single rows or columns, a list of rows/columns, or conditional expression within those brackets\n",
        "- Select specific rows and/or columns using `loc` when working with row/column names\n",
        "- Select specific rows and/or columns usign `iloc` when working with index positions\n",
        "- You can assign new values to selection using `loc` or `iloc`\n",
        "\n",
        "## From `DataFrame` to Data File\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=bbd847e6-f649-43fb-ad8c-af3601480776\">From DataFrame to Data File</a></td>\n",
        "  </tr>\n",
        "  </table>\n",
        "\n",
        "Let's say we have data in a `DataFrame` and want to write that to a file. While `.read_` loads data, `.to_` writes data.\n",
        "\n",
        "Let's say we want to save our filtered `DataFrame` as an Excel file."
      ],
      "metadata": {
        "id": "dzwOmGJvtLz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(\"df.xlsx\", sheet_name=\"data\", index=False)"
      ],
      "metadata": {
        "id": "V716hSzItMy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we create a new Excel file with a single sheet (`data`) that stores the data from our `df` `DataFrame`. `index=False` means that row index labels are not included in the new spreadsheet.\n",
        "\n",
        "We could load back in the new Excel file and write it to a `.csv` file, dropping the header row:"
      ],
      "metadata": {
        "id": "zWNjRi3ytOU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load Excel file as dataframe\n",
        "df = pd.read_excel(\"df.xlsx\", sheet_name=\"data\")\n",
        "\n",
        "# write dataframe to CSV file with no header\n",
        "df.to_csv(\"df.csv\", header=False, index=False)"
      ],
      "metadata": {
        "id": "29AvfJoXtRfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "Q7A: Load a structured data file as a `DataFrame`. You're welcome to use your own data file, the file from Thursday's in-class work, or the `sample-data.csv` file provided with this lab ([GitHub](https://github.com/kwaldenphd/football-structured-data/blob/main/background.md#football-rosters), [Google Drive](https://drive.google.com/file/d/1uDNxiBx2gVRmIPR3Ka3-jLguNkcl1LqC/view?usp=sharing)).\n",
        "- [Click here](https://github.com/kwaldenphd/football-structured-data/blob/main/background.md#football-rosters) for more background on the sample data.\n",
        "\n",
        "Q7B: Using the DataFrame you created for Q7A, write code that accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Shows the first five rows\n",
        "- Shows the last five rows\n",
        "- Checks the data types for each column\n",
        "- Returns a technical summary for the DataFrame\n",
        "\n",
        "Q7C: Using the DataFrame you created for Q7A, write code that executes AT LEAST FOUR (4) of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Sorts a column by ascending values\n",
        "- Sorts a column by descending values\n",
        "- Selects a specific column in the DataFrame\n",
        "- Creates a new DataFrame with select columns from existing DataFrame\n",
        "- Uses a comparison operator to filter rows in the DataFrame\n",
        "- Uses an isin statement to filter rows in the DataFrame\n",
        "- Selects specific rows and columns"
      ],
      "metadata": {
        "id": "V0Rt_vPNtTDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Other `DataFrame` Tasks\n",
        "\n",
        "<table>\n",
        " <tr><td>\n",
        "<img src=\"https://elearn.southampton.ac.uk/wp-content/blogs.dir/sites/64/2021/04/PanPan.png\" alt=\"Panopto logo\" width=\"50\"/></td>\n",
        "<td><a href=\"https://notredame.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=71580603-99cd-46f6-bfa3-af360147553e\">Other DataFrame Tasks</a></td>\n",
        "  </tr>\n",
        "  </table>\n"
      ],
      "metadata": {
        "id": "min4U0QHtT3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Duplicates\n",
        "\n",
        "A useful place to start is identifying and removing any duplicate rows in a dataframe. We can do this using a few key functions. `.duplicated()` will return a `True` or `False` value indicating if a row is a duplicate of a previously occuring row."
      ],
      "metadata": {
        "id": "9n8pbWD5tiQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame.duplicated()"
      ],
      "metadata": {
        "id": "GZxFFNSItj8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.drop_duplicates()` will return a dataframe containing only rows that are not duplicated."
      ],
      "metadata": {
        "id": "f0onWUbCtk4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_frame = old_data_frame.drop_duplicates()"
      ],
      "metadata": {
        "id": "L9InseA_tliJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "As mentioned previously, we can specify how `pandas` handles missing values when working with a data frame object."
      ],
      "metadata": {
        "id": "FbJBniJStm5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `.dropna()`\n",
        "\n",
        "We can use `.dropna()` to drop any row containing a missing value:"
      ],
      "metadata": {
        "id": "f9PJXvKBtn8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_na = data_frame.dropna()"
      ],
      "metadata": {
        "id": "XARETyHNtor3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To drop any column containing a missing value, we can specify the axis:"
      ],
      "metadata": {
        "id": "F_krkI7ztp4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_na_columns = data_frame.dropna(axis=1, how='all')"
      ],
      "metadata": {
        "id": "A0c4UZPutqoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `.fillna()`\n",
        "\n",
        "But we can imagine a scenario in which you don't want to filter out missing data. The `.fillna()` function will replace missing data with a specified value. The default function will replace all missing data in the dataframe:\n"
      ],
      "metadata": {
        "id": "u2TVAmDRtsJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replaces all missing data with 0\n",
        "df.fillna(0)"
      ],
      "metadata": {
        "id": "h9QL0xR2ts6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also specify a different missing fill value for specific columns using a dictionary."
      ],
      "metadata": {
        "id": "Tp6TpDGfttlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace missing data in column 1 with 0.5 value and in column 2 with 0\n",
        "df.fillna({1: 0.5, 2: 0})"
      ],
      "metadata": {
        "id": "LRgrYb_3tujC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In these examples, `.fillna()` returns a new object, but we can also modify the existing object in-place by setting `inplace` to `True`."
      ],
      "metadata": {
        "id": "dY2WwotYtvl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify existing object in-place\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "NAbor-OQtwON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also copy (or propogate) the last valid observation into missing data using specific methods that go along with `.fillna()`.\n",
        "- Fill Forward (`ffill`) will take the \"last known value\" and apply it to missing data entries, until you hit the next non-null observation in the data frame.\n",
        "- Back Fill (`bfill`) goes the other direction, starting from the last row in the dataset. The \"last known value\" is applied to missing data entries until you hit the next non-null observation.\n",
        "\n",
        "To use forward fill on all missing values in a dataframe:"
      ],
      "metadata": {
        "id": "0Lb4rE6htxU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(method='ffill')"
      ],
      "metadata": {
        "id": "Ho69ZWHbtyBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use back fill on all missing values in a dataframe:"
      ],
      "metadata": {
        "id": "dl6qkgyttyqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(method='bfill')"
      ],
      "metadata": {
        "id": "bNl4TTx8tzS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "Q8A: Using the DataFrame you created for Q7, write code that executes AT LEAST ONE of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "- Removes duplicate rows\n",
        "- Removes rows with missing values\n",
        "- Fills missing values using .fillna, ffill, or bfill\n",
        "\n",
        "Q8B: Write your modified `DataFrame` from Q8A to a `.csv` file. Your answer for these items should include a Python program + comments that document process and explain your code.\n"
      ],
      "metadata": {
        "id": "9UsCZ4ANt0dy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to submit this lab (and show your work)\n",
        "\n",
        "Moving forward, we're going to be submitting lab notebooks using the provide Jupyter Notebook template.\n",
        "- If working in JupyterLab (or another desktop IDE), download the `.ipynb` file to your local computer\n",
        "  * `File` - `Download` - `Download as .ipynb`\n",
        "- If working in Google Colaboratory, MAKE SURE you save a copy to your local drive. Otherwise your changes will not be saved.\n",
        "  * `File` - `Save a copy in Drive`\n",
        "\n",
        "The lab notebook template includes all of the questions as well as pre-created markdown cells for narrative text answers and pre-created code cells for any programs you may need to create.\n",
        "- Double click on these cells to edit and add your own content\n",
        "- If questions do not require a code component, you can ignore those cells\n",
        "- If questions to not require a narrative component, you can ignore those cells\n",
        "\n",
        "If working in JupyterLab or another desktop IDE, upload the lab notebook template `.ipynb` file to Canvas as your lab submission.\n",
        "\n",
        "If working in Google Colaboratory, submit the link to your notebook (checking sharing permissions, similar with Google Docs)."
      ],
      "metadata": {
        "id": "9aLGmNwGhDF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Notebook Questions\n",
        "\n",
        "[Click here](https://colab.research.google.com/drive/1w6rrEM6I69TIdm-WpSDrEMgMC26bTzdj?usp=sharing) to access the lab notebook template as a Jupyter Notebook.\n",
        "\n",
        "Q1A: Create a small list data structure and write it to a CSV file. Answer to this question includes program + comments that document process and explain your code.\n",
        "\n",
        "Q1B: Create a small dictionary and write it to a CSV file. Answer to this question includes program + comments that document process and explain your code.\n",
        "\n",
        "Q2: Decipher what we're seeing in the JSON here. What are some of the name/value pairs, and how are they organized in this object?\n",
        "\n",
        "```JSON\n",
        "{\n",
        "  \"created_at\": \"Thu Apr 06 15:24:15 +0000 2017\",\n",
        "  \"id_str\": \"850006245121695744\",\n",
        "  \"text\": \"1\\/ Today we\\u2019re sharing our vision for the future of the Twitter API platform!\\nhttps:\\/\\/t.co\\/XweGngmxlP\",\n",
        "  \"user\": {\n",
        "    \"id\": 2244994945,\n",
        "    \"name\": \"Twitter Dev\",\n",
        "    \"screen_name\": \"TwitterDev\",\n",
        "    \"location\": \"Internet\",\n",
        "    \"url\": \"https:\\/\\/dev.twitter.com\\/\",\n",
        "    \"description\": \"Your official source for Twitter Platform news, updates & events. Need technical help? Visit https:\\/\\/twittercommunity.com\\/ \\u2328\\ufe0f #TapIntoTwitter\"\n",
        "  },\n",
        "  \"place\": {   \n",
        "  },\n",
        "  \"entities\": {\n",
        "    \"hashtags\": [      \n",
        "    ],\n",
        "    \"urls\": [\n",
        "      {\n",
        "        \"url\": \"https:\\/\\/t.co\\/XweGngmxlP\",\n",
        "        \"unwound\": {\n",
        "          \"url\": \"https:\\/\\/cards.twitter.com\\/cards\\/18ce53wgo4h\\/3xo1c\",\n",
        "          \"title\": \"Building the Future of the Twitter API Platform\"\n",
        "        }\n",
        "      }\n",
        "    ],\n",
        "    \"user_mentions\": [     \n",
        "    ]\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "Q3: Create a string of JSON data and write it to a JSON file. Answer to this question includes program + comments that document process and explain your code.\n",
        "\n",
        "Q4: Create your own `Series` object. Write code the accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Assign unique index attributes for each series value\n",
        "- Access a series value(s) using the index label\n",
        "- Perform at least two unique arithmetic operations on the Series\n",
        "- Test for null values in your series\n",
        "\n",
        "Q5: Create your own small DataFrame. Write code that accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Change the original column order\n",
        "- Select a specific column(s) using its index label or name attribute\n",
        "- Select a specific row(s) using its index label or index value\n",
        "- Remove a column from the DataFrame\n",
        "- Determine summary statistics for values in the DataFrame\n",
        "\n",
        "<blockquote>For the Q6 programs, you do not need to write code that actually loads an existing data file. That is, the lab does not provide data files that include these structures/attributes.\n",
        "<br><br>\n",
        "Write sample code that shows the syntax you would use to load a file with the structures/attributes described in the question.</blockquote>\n",
        "\n",
        "Q6A: Write code that loads in a structured data file that uses a pipe symbol (|) as a delimiter. Include code + comments.\n",
        "\n",
        "Q6B: Write code that loads in structured data file in which missing data values are represented by \"?\", \"??\", and \"-\" characters. Include code + comments.\n",
        "\n",
        "Q6C: Write code that ignores the last 6 rows of a structured data file. Include code + comments.\n",
        "\n",
        "Q6D: Write code that parses a structured data file in which commas \",\" are used as a thousands separator. Include code + comments.\n",
        "\n",
        "Q7A: Load a structured data file as a `DataFrame`. You're welcome to use your own data file, the file from Thursday's in-class work, or the `sample-data.csv` file provided with this lab ([GitHub](https://github.com/kwaldenphd/football-structured-data/blob/main/background.md#football-rosters), [Google Drive](https://drive.google.com/file/d/1uDNxiBx2gVRmIPR3Ka3-jLguNkcl1LqC/view?usp=sharing)).\n",
        "- [Click here](https://github.com/kwaldenphd/football-structured-data/blob/main/background.md#football-rosters) for more background on the sample data.\n",
        "\n",
        "Q7B: Using the DataFrame you created for Q7A, write code that accomplishes the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Shows the first five rows\n",
        "- Shows the last five rows\n",
        "- Checks the data types for each column\n",
        "- Returns a technical summary for the DataFrame\n",
        "\n",
        "Q7C: Using the DataFrame you created for Q7A, write code that executes AT LEAST FOUR (4) of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "- Sorts a column by ascending values\n",
        "- Sorts a column by descending values\n",
        "- Selects a specific column in the DataFrame\n",
        "- Creates a new DataFrame with select columns from existing DataFrame\n",
        "- Uses a comparison operator to filter rows in the DataFrame\n",
        "- Uses an isin statement to filter rows in the DataFrame\n",
        "- Selects specific rows and columns\n",
        "\n",
        "Q8A: Using the DataFrame you created for Q7, write code that executes AT LEAST ONE of the following tasks. Your answer for these items should include a Python program + comments that document process and explain your code.\n",
        "\n",
        "- Removes duplicate rows\n",
        "- Removes rows with missing values\n",
        "- Fills missing values using .fillna, ffill, or bfill"
      ],
      "metadata": {
        "id": "SEYXwrwdT5_S"
      }
    }
  ]
}